{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Load All the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(metadata_file):\n",
    "    with open(metadata_file, 'r') as file:\n",
    "        metadata = json.load(file)\n",
    "    return metadata\n",
    "\n",
    "def load_transcript(transcript_file, metadata):\n",
    "    with open(transcript_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    transcript_text = \"\"\n",
    "\n",
    "    for channel in data['results']['channels']:\n",
    "        for alternative in channel['alternatives']:\n",
    "            for word_info in alternative['words']:\n",
    "                word = word_info['punctuated_word']\n",
    "                transcript_text += word + \" \"\n",
    "    \n",
    "    video_id = data['metadata']['sha256']\n",
    "    title = metadata.get('title', 'Unknown Title')\n",
    "    \n",
    "    return {\n",
    "        \"text\": transcript_text.strip(),\n",
    "        \"metadata\": {\n",
    "            \"video_id\": video_id,\n",
    "            \"title\": title\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Make chunks of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_transcript(transcript, max_chunk_size, overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "        separators=['.', ',', '\\n', '\\n\\n']\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(transcript['text'])\n",
    "    \n",
    "    chunked_data = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_data.append({\n",
    "            \"chunk_id\": f\"{transcript['metadata']['video_id']}_{i}\",\n",
    "            \"title\": transcript['metadata']['title'],\n",
    "            \"text\": chunk.strip()\n",
    "        })\n",
    "\n",
    "    return chunked_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Now Save the Chunks into json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chunks saved to: Chunks\\chunks.json\n"
     ]
    }
   ],
   "source": [
    "def save_chunks_to_file(combined_chunks, output_file):\n",
    "    output_dir = \"Chunks\"\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file_path = os.path.join(output_dir, output_file)\n",
    "    \n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(combined_chunks, file, indent=4)\n",
    "    \n",
    "    print(f\"All chunks saved to: {output_file_path}\")\n",
    "\n",
    "videos_directory = os.path.join(\"transcripts\", \"videos\")\n",
    "combined_chunks = []\n",
    "\n",
    "for video_folder in os.listdir(videos_directory):\n",
    "    video_path = os.path.join(videos_directory, video_folder)\n",
    "    transcript_path = os.path.join(video_path, \"transcript.json\")\n",
    "    metadata_path = os.path.join(video_path, \"metadata.json\")\n",
    "    \n",
    "    if os.path.isfile(transcript_path) and os.path.isfile(metadata_path):\n",
    "        metadata = load_metadata(metadata_path)\n",
    "        transcript = load_transcript(transcript_path, metadata)\n",
    "        chunked_data = chunk_transcript(transcript, max_chunk_size=800, overlap=100)\n",
    "        combined_chunks.extend(chunked_data)\n",
    "\n",
    "save_chunks_to_file(combined_chunks, \"chunks.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Create Embeddings and store these into vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chunks from: e:\\ML and Data Science work\\Challenge\\datawars-llm-challenges\\Chunks\\chunks.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding = OpenAIEmbeddings(api_key=api_key)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "chunk_file_path = os.path.join(current_dir, \"Chunks\", \"chunks.json\")\n",
    "print(f\"Loading chunks from: {chunk_file_path}\")\n",
    "\n",
    "# Load the chunks\n",
    "with open(chunk_file_path, \"r\") as file:\n",
    "    chunks = json.load(file)\n",
    "\n",
    "\n",
    "# Convert chunks to Document objects\n",
    "documents = [Document(page_content=chunk[\"text\"], metadata=chunk) for chunk in chunks]\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=documents, embedding=embedding, persist_directory='./chroma_db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Set up retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrive Relavent Documents\n",
      "Metadata:\n",
      "chunk_id: 90912b0487bb8ee8331333237b0103d9dc06f1c317ff932fcdc9f44b1a76d489_22\n",
      "text: . So, this object contains a bunch of groups, and to better understand what this is, let's take a look at an individual group, that this DataFrame has. Now, before we do that, I am going to set this as a variable so that we can reuse this, and not have to retype our code over and over, and also it will be easier to read. So I am going to call this country group, and I'm just going to set this equal to this df.groupby. And now, instead of typing this every time, we can just reference this country group variable here. So now let's take a look at one of these groups. So since we grouped our rows by country, then we can grab a specific group by country name. So I'll grab the group for the United States\n",
      "title: Python Pandas Tutorial (Part 8): Grouping and Aggregating - Analyzing and Exploring Your Data\n",
      "\n",
      "Metadata:\n",
      "chunk_id: 90912b0487bb8ee8331333237b0103d9dc06f1c317ff932fcdc9f44b1a76d489_21\n",
      "text: . Okay. So now let's look at how to use the group by function on our country column. So first we're going to split the object, and then we're going to apply a function, and then it will combine those results. So first, let's look at splitting the object. Now, in this case, we want to group all of the results by country. So to do this, we can simply say, df.groupby, and then we will pass in, this is going to be a list of columns that we want to group on. And I'm just gonna pass in a single column here for country. So if I run this, then what we get back here is this data frame group by object. So what is this object, and what exactly can we do with this? So first, let's explain a bit what this is\n",
      "title: Python Pandas Tutorial (Part 8): Grouping and Aggregating - Analyzing and Exploring Your Data\n",
      "\n",
      "Metadata:\n",
      "chunk_id: 90912b0487bb8ee8331333237b0103d9dc06f1c317ff932fcdc9f44b1a76d489_19\n",
      "text: . So first of all, if we want to see specific results based on the country or based on some other column, then we are going to have to group on that specific column. And we have the group by function for this. So what actually does it mean to say that we are going to use the groupby function? So in the Pandas documentation, it says that a groupby operation involves, some combination of splitting the object, applying a function, and combining the results. So I'm gonna try to walk through each of those processes one at a time so that we can see exactly how this works. So again, in the Pandas documentation, it says that a group by operation involves some combination of splitting up our object, applying a function, and then combining those results. So let's do each of those\n",
      "title: Python Pandas Tutorial (Part 8): Grouping and Aggregating - Analyzing and Exploring Your Data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Perform a retrieval\n",
    "response = retriever.invoke(\"HOW TO GROUP A DATAFRAME IN PANDAS?\")\n",
    "\n",
    "print(\"Retrive Relavent Documents\")\n",
    "for result in response:\n",
    "    print(\"Metadata:\")\n",
    "    for key, value in result.metadata.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As you can see it retrieve the relevant result from the chunks. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰Creating the LLM-powered RAG Chain for Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM with the API key\n",
    "llm = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "human\n",
    "\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {input} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘‰ Now Generate Response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To group a DataFrame in Pandas, we use the \"groupby\" function and specify the column we want to group by. This will return a new object with the groups as its index. We can then access a specific group using the \"get_group\" function and specifying the group name. This allows us to easily work with and manipulate our data based on groups.\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I group a DataFrame in Pandas?\"\n",
    "\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "# Print the response\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
